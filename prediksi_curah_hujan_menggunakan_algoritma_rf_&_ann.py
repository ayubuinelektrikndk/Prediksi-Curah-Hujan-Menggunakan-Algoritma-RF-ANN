# -*- coding: utf-8 -*-
"""Prediksi Curah Hujan Menggunakan Algoritma RF & ANN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t-cLe-TKXOFJAJieSzNM5GFTJwyNNhjC
"""

from google.colab import files
uploaded = files.upload()

"""# Data Processing and Analysis

## Data Processing
"""

import pandas as pd

# Memberi nama pada header
colnames = ["timestamp","ptemp_c","rh","rain_mm_tot","radiasi_avg"]
# Data masih permenit
df = pd.read_csv("Bandung Hourly.csv", sep=";", names=colnames)
df

# Untuk Menampilkan count,mean,std,min,25%,50%,75% dan max
df.describe()

# Mengubah'timestamp' menjadi 'date'
df["date"] = df.timestamp.apply(lambda t: t.split(" ")[0])
df["date"] = df.date.apply(lambda t: "/".join(reversed(t.split("/"))))
df

# Mencari rata-rata dari semua data fitur kecuali rain_mm_tot
df2 = df[["date","ptemp_c","rh","radiasi_avg"]]
df2 = df2.groupby("date").mean().reset_index()
df2

# Menjumlahkan semua data fitur "rain_mm_tot"
df3 = df[["date","rain_mm_tot"]]
df3 = df3.groupby("date").sum().reset_index()
df3

# Menggabungkan data fitur yang sudah di rata-ratakan dan data fitur yang sudah dijumlahkan
df = pd.merge(df2,df3, on="date")
df

# Kategori Hujan 
def generate_label(rain_density):
    if rain_density < 0.5:
        return "Berawan"
    elif 0.5 <= rain_density < 20:
        return "Hujan Ringan"
    elif 20 <= rain_density < 50:
        return "Hujan Sedang"
    elif 50 <= rain_density < 100:
        return "Hujan Lebat"
    elif 100 <= rain_density < 150:
        return "Hujan Sangat Lebat"
    elif  rain_density >= 150:
        return "Hujan Ekstrem"


df["label"] = df.rain_mm_tot.apply(generate_label)
df

# Untuk mengetahui jumlah kategori perlabel
col_names = ["label"]

for col in col_names:
    
    print(df[col].value_counts())

"""## Data Visualization

### Correlation
"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.style.use("seaborn-whitegrid")

plt.figure(figsize=(12, 12))
heatmap = sns.heatmap(df.iloc[:, 1:-1].corr(), annot=True, annot_kws={"size": 24})
heatmap.set_xticklabels(heatmap.get_xmajorticklabels(), fontsize=16)
heatmap.set_yticklabels(heatmap.get_ymajorticklabels(), fontsize=16)
colorbar = heatmap.collections[0].colorbar
colorbar.ax.tick_params(labelsize=16)
plt.savefig("correlation.png")

"""### Histogram"""

plt.figure(figsize=(20, 20))
for i, col in enumerate(df.columns[1:-1]):
    plt.subplot(2, 2, i + 1)
    sns.histplot(data=df, x=col, hue="label")
plt.savefig("distribution.png")

"""### Label Distribution"""

plt.figure(figsize=(12, 8))
sns.countplot(data=df, x="label")
plt.savefig("labeldist.png")

"""## Data to Features"""

label_to_idx = {v: k for k, v in enumerate(sorted(df.label.unique()))}
idx_to_label = sorted(df.label.unique())
X = df.iloc[:, 1:-1]
y = df.iloc[:, -1].apply(lambda l: label_to_idx[l])

"""## Modelling Library"""

import time
import random
import numpy as np
from time import time
from sklearn import metrics
from sklearn import model_selection
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

"""### Random Forest"""

random.seed(2022)
np.random.seed(2022)
rf = RandomForestClassifier(n_estimators=100, max_depth=10)

elapsed_train_time = []
elapsed_test_time = []
scores = []
for idx_train, idx_test in model_selection.StratifiedKFold(3).split(X, y):
    X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]
    y_train, y_test = y.iloc[idx_train], y.iloc[idx_test]

    X_mean = np.mean(X_train, axis=0)
    X_std = np.mean(X_train, axis=0)

    X_train = (X_train - X_mean) / X_std
    X_test = (X_test - X_mean) / X_std

    start_time = time()
    rf.fit(X_train, y_train)
    elapsed_train_time.append(time() - start_time)

    start_time = time()
    y_pred = rf.predict(X_test)
    end_time = time() - start_time

    elapsed_test_time.append(time() - start_time)

    scores.append(
        metrics.classification_report(
            y_test, y_pred, target_names=idx_to_label, zero_division=0, output_dict=True
        )
    )

running_mean_train = np.mean(elapsed_train_time).round(4)
running_std_train = np.std(elapsed_train_time).round(4)
print("Training Time (s)")
print(f"Mean: {running_mean_train}")
print(f"Standard Deviation: {running_std_train}")

running_mean_test = np.mean(elapsed_test_time).round(4)
running_std_test = np.std(elapsed_test_time).round(4)
print("Testing Time (s)")
print(f"Mean: {running_mean_test}")
print(f"Standard Deviation: {running_std_test}")

scores = pd.json_normalize(scores, sep=" ")
scores.columns = [t.title() for t in scores.columns]
scores = scores.round(4) * 100
scores["Training Time"] = elapsed_train_time
scores["Testing Time"] = elapsed_test_time

scores.to_excel("rfscores.xlsx")
scores

result = pd.DataFrame(
    [scores.mean(axis=0), scores.std(axis=0)], index=["Mean", "Standard Deviation"]
)
result = result[
    [
        col
        for col in result.columns
        if "F1-Score" in col
        or "Precision" in col
        or "Recall" in col
        or "Accuracy" in col
        or col == "Training Time"
        or col == "Testing Time"
    ]
].T

result.to_excel("rfresult.xlsx")
result

"""### Artificial Neural Network"""

random.seed(2022)
np.random.seed(2022)
mlp = MLPClassifier(hidden_layer_sizes=200, learning_rate_init=1e-2)

elapsed_train_time = []
elapsed_test_time = []
scores = []
for idx_train, idx_test in model_selection.StratifiedKFold(3).split(X, y):
    X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]
    y_train, y_test = y.iloc[idx_train], y.iloc[idx_test]

    X_mean = np.mean(X_train, axis=0)
    X_std = np.mean(X_train, axis=0)

    X_train = (X_train - X_mean) / X_std
    X_test = (X_test - X_mean) / X_std

    start_time = time()
    mlp.fit(X_train, y_train)
    elapsed_train_time.append(time() - start_time)

    start_time = time()
    y_pred = mlp.predict(X_test)
    end_time = time() - start_time

    elapsed_test_time.append(time() - start_time)

    scores.append(
        metrics.classification_report(
            y_test, y_pred, target_names=idx_to_label, zero_division=0, output_dict=True
        )
    )

X_train.shape[0] , y_test.shape[0]

running_mean_train = np.mean(elapsed_train_time).round(4)
running_std_train = np.std(elapsed_train_time).round(4)
print("Training Time (s)")
print(f"Mean: {running_mean_train}")
print(f"Standard Deviation: {running_std_train}")

running_mean_test = np.mean(elapsed_test_time).round(4)
running_std_test = np.std(elapsed_test_time).round(4)
print("Testing Time (s)")
print(f"Mean: {running_mean_test}")
print(f"Standard Deviation: {running_std_test}")

scores = pd.json_normalize(scores, sep=" ")
scores.columns = [t.title() for t in scores.columns]
scores = scores.round(4) * 100
scores["Training Time"] = elapsed_train_time
scores["Testing Time"] = elapsed_test_time
scores = scores.round(4)

scores.to_excel("mlpscores.xlsx")
scores

result = pd.DataFrame(
    [scores.mean(axis=0), scores.std(axis=0)], index=["Mean", "Standard Deviation"]
)
result = result[
    [
        col
        for col in result.columns
        if "F1-Score" in col
        or "Precision" in col
        or "Recall" in col
        or "Accuracy" in col
        or col == "Training Time"
        or col == "Testing Time"
    ]
].T

result.to_excel("mlpresult.xlsx")
result

df_rf = pd.read_excel("rfresult.xlsx").rename(
    {
        "Unnamed: 0": "Metric",
        "Mean": "Mean (RF)",
        "Standard Deviation": "Standard Deviation (RF)",
    },
    axis=1,
)
df_mlp = pd.read_excel("mlpresult.xlsx").rename(
    {
        "Unnamed: 0": "Metric",
        "Mean": "Mean (MLP)",
        "Standard Deviation": "Standard Deviation (MLP)",
    },
    axis=1,
)

df_score = pd.merge(df_rf, df_mlp, on="Metric")
df_score.to_excel("result.xlsx", index=False)
df_score